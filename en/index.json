[
{
	"uri": "localhost:1313/en/connecting_guide/human_ix/conn_string_uri/",
	"title": "Connection string URI",
	"tags": [],
	"description": "MongoDB connection URI syntax",
	"content": " Ladies and gentlemen, I present to you (drum roll) the standard MongoDB connection string URI:\nmongodb://[user[:password]@]host[:port][,host[:port]]*[/[database_name][?[conn_option[=value]][,conn_option[=value]]*]]\nAt this point I expect all readers fall into one of following three groups:\n 'Yuck. Punctuation vomit or what?' 'Ah, a URI like those ones for ODBC / Postgresql / MS SQL server / MySQL etc. ...' 'You've neglected the DNS/SRV seedlist format, moron'  If you are in group #1 I'm sorry but I can't 'sexy it up' in any way, no matter how hard I try. At it's simplest the URI you type is short and easy, but as you add authentication credentials and options it can't help becoming more and more verbose.\nIf you are in group #2 one special difference to note is that multiple host+port tuples can be accepted, instead of just one. More on this in theReplicaset host-list syntax section below.\nIf you are in group #3, cool, you're done, you don't need this page and you can move onto the next. (And I'll say I'm envious that you've been given enough privileges to add and modify SRV records on your DNS servers.)\nNon-URI formats You may have used (or will see on other sites) ways to connect without using the URI format. E.g. with the shell mongo --host myhost.my.domain:27018, or a code sample something like var conn = new MongoClient(\u0026quot;myhost.my.domain\u0026quot;, 27018)'.\nThese are just for legacy compatibility and/or to give some abbreviation. In reality those arguments will be immediately reformatted into a new 'mongodb://...' string and that is what the driver code will use.\nAs well as being deprecated the non-URI formats differ in syntax from one language driver to another. Let's just stop thinking about them a.s.a.p.\nExamples Basic / minimal To make a new connection a MongoDB client needs at least the two things any TCP connection requires - a hostname (or it's IP address) and a port.\nmongodb://myhost.my.domain:27017/\nWhat if host or port are wrong or the MongoDB server can't be reached because of a network problem? The TCP connection will never be established and the error message will be something along those lines. E.g. 'socket exception', and not 'MongoDB server failure'.\nAdding access credentials If the DB requires users to authenticate with username and password then add those too, delimited by \u0026quot;:\u0026quot; and suffixed with \u0026quot;@\u0026quot;.\nmongodb://akira:secret@myhost.my.domain:27017/\nIf you have tricky punctuation characters in your password that would wreck the URI parsing (i.e. \u0026quot;/\u0026quot;, \u0026quot;:\u0026quot;, \u0026quot;@\u0026quot;, or \u0026quot;%\u0026quot;) encode those with percent encoding. E.g. \u0026quot;EatMyH@t\u0026quot; -\u0026gt; \u0026quot;EatMyH%40t\u0026quot;.\n By default/convention the user authentication credentials are saved in the \u0026quot;admin\u0026quot; db on the server. This is the assumed default for mongodb connection URIs too, so you can leave it absent (as above) most of the time.\nBut if the \u0026quot;akira\u0026quot; user authentication credentials had been created in in the \u0026quot;orderhist\u0026quot; user databases then that db name is needed as shown below. The first format sets the starting db namespace (that commands such as find, db stats, etc. will act in) as \u0026quot;orderhist\u0026quot; and the auth source db is assumed to be the same. The second format allows for the starting db namespace to be something else.\nmongodb://akira:secret@myhost.my.domain:27017/orderhist\nmongodb://akira:secret@myhost.my.domain:27017/[some_other_db]?authSource=orderhist\nI do not recommended created user auth outside the \u0026quot;admin\u0026quot; db \u0026ndash; the above is just for reference in case you are accessing a non-conventional MongoDB cluster or replica set.\n What if the user credentials are rejected (e.g. unknown username or wrong password)? The TCP socket connection will be established for a moment. Over the TCP connection the username and it's hashed password will be sent. If they fail the server will send the failure reply ('user unauthorized', etc.) in a MongoDB Wire protocol OP_REPLY (or rereply OP_MSG?), then close the socket immediately.\nQ. \u0026quot;What if the MongoDB server requires user authentication but the client fails to give username and password?\u0026quot;\nUnintuitively the TCP connection will be established and stay open! It will remain open to allow the client to send db user credentials. Any command other than authenticate or the ones drivers need for basic state detection (isMaster, hostInfo, etc.) will be rejected with an authorization error.\nConnection options For convenience the full syntax again:\nmongodb://[user[:password]@]host[:port][,host[:port]]*[/[database_name][?[conn_option[=value]][,conn_option[=value]]*]]\nAfter the \u0026quot;/\u0026quot; that follows host[:port] all the values are optional. The first is the user_auth_db_name (see above), then whether that db name is present or not put \u0026quot;?\u0026quot; before any other parameters. Delimit with an \u0026quot;\u0026amp;\u0026quot;, like in a HTTP URI.\nExample If the DB was configured to accept connections that use SSL network encryption then from the client side we add the \u0026quot;ssl=true\u0026quot; to instruct the driver to do that. If we want the driver to make a pool of at least 50 database connections that different threads in the application can share, then we could add \u0026quot;minPoolSize=50\u0026quot;.\nmongodb://akira:secret@myhost.my.domain:27017/?ssl=true\u0026amp;minPoolSize=50\nStaring in v4.2 there is general renaming of \u0026quot;SSL\u0026quot; as \u0026quot;TLS\u0026quot; in mongod/mongos server node and mongo shell options, and the MongoDB documentation in general (link). It seems the connection string URI options are going to remain ssl* though.\n Most common options ... as I recall seeing / expect should be used.\n replicaSet. Invalid if connecting to a sharded cluster. But otherwise use this ensure you establish a replicaset connection that will failover in the event of a primary switch, rather than just having a standalone connection. authSource readPreference N.b. I'd recommend not using this; i.e. always use the default, which is doing reads only from primaries. But I know many users do secondary reads (I hypothesize a habit learned from completely different, non-db systems that have load balancers) and this is the option for setting that. w (write concern level) connectTimeoutMS retryWrites If there is a primary switch this will automatically retry once (but only once) any writes to the old primary that errored because it crashed / was stepped down in the middle of the first attempt.  The (one) connection parameter that can't go in the URI Using the \u0026quot;ssl=true\u0026quot; option in my example above requires me to point out that, unfortunately, one of the SSL options (but so far only this one) need to be passed to the client connection function outside of URI. SSL connections usually require a CA cert file and/or a client certificate file to be used, and you can't put a local filepath into an URI. (Well maybe you can, but this isn't standardizedyet.)\nA C++ driver example of adding an SSL client PEM file is shown below. The point is simply that the minimal case of needing just one line with the URI connection in it is no longer possible; we have to prepare and add an extra connection option alongside it when the client connection object is constructed.\nmongocxx::options::ssl ssl_opts{}; ssl_opts.pem_file(\u0026quot;client.pem\u0026quot;); mongocxx::options::client client_opts{}; client_opts.ssl_opts(ssl_opts); auto client = mongocxx::client{uri{\u0026quot;mongodb://host1/?..\u0026lt;other_parameters\u0026gt;..\u0026amp;ssl=true\u0026quot;}, client_opts};  Replicaset host-list syntax The MongoDB connection URIs above could be syntactically valid as HTTP URLs if we simply replace \u0026quot;mongodb\u0026quot; with \u0026quot;http\u0026quot;, but it isn't always so. There is one key HTTP-like rule-breaker which is necessitated by the fact that MongoDB typically uses replica sets. If a replica set has hosts hostA, hostB and hostC, each using the same port 27017, then the URI can accept them in a comma-separated list:\nmongodb://akira:secret@hostA:27017,hostB:27017,hostC:27017/?ssl=true\u0026amp;minPoolSize=50\nIf you only specify one host (let's say hostA:27017) that the driver can connect to it will automatically query for the full replica set configuration/status. After that it will be aware of all the other hosts, so it might seem unnecessary to specify multiple hosts to connect to. But imagine a time when hostA was shut down for maintenance, or had crashed, and the client has to establish a new connection.\nDefaults Most of of the URI parameters have default values.\nMost useful to know is that the hostname default is localhost, and the port default is 27017. It's these that make it possible for clients to connect without specifying any connection options at all. All you need to do is to set up a mongod or mongos process running on port 27017 with no user authentication on the same server as the client.\n"
},
{
	"uri": "localhost:1313/en/connecting_guide/cs_nw_details/drivers/",
	"title": "Drivers and &#39;the wire&#39;",
	"tags": [],
	"description": "Putting perspective on what a MongoDB driver is through a description of the shape and behaviour of your client requests (and server replies) as TCP traffic",
	"content": " From the perspective of the driver developer a MongoDB driver:\n Marshalls data from the language's native types into the format the MongoDB server requires (== a BSON payload proceeded by a few classically simple network fields in each packet's header area). Sends and receives that info, keeping track of which reply from a server matches which request.  When using a connection pool it also keeps a track of which thread the requests were sent from  Goes to error handling when there are network interruptions like abrupt socket closure and other TCP casuality situations Implements a lot of detail in the 'Meta' API driver specification for server discovery and monitoring (\u0026quot;SDAM\u0026quot;) and server selection.  From the application developer's perspective the MongoDB driver:\n Presents the database as an object you can push data in and pull data out of. The API provided is idiomatic for your language. E.g. where Java programmers run a find() method on a collection object, C driver users run a mongoc_collection_find() function that takes a mongoc_collection_t* pointer argument, etc.  To look at it from another side this is what the driver API doesn't do:\n Involve the application programmer in maintaining the TCP socket connections. Involve the application programmer in determining which remote servers are the current primaries (i.e. the one that the writes happen on first) Expose network packet data in the wire protocol format  Apart from the fact that you open a connection, and there can be exceptions thrown when a server crashes or the network is disconnected, there is limited expression in the API that the database is on a remote server. There are no network-conscious concepts the user must engage with such as 'queue this request', 'pop reply off incoming message stack', etc.\nRegardless of which driver you are using, at the Wire Protocol layer they are all the same fundamentally. If they are contemporary versions there's a good chance the BSON payload in each Wire protocol packet is identical excluding ephemeral fields like a timestamps.\nThe format of data in MongoDB Wire Protocol requests and responses is relatively simple, but it is a binary one and is far from being human-readable. The below comes from TCP payloads captured using tcpdump, manually unwrapped using command line tools od and bsondump according to the info in the MongoDB wire protocol documentation.\n   Example find in various APIs  MongoDB wire packet  mongod code     mongo shell db.foo.find({\u0026quot;x\u0026quot;: 99};\nPyMongo db.foo.find({\u0026quot;x\u0026quot;: 99})\nJava db.getCollection(\u0026quot;foo\u0026quot;).find(eq(\u0026quot;x\u0026quot;, 99))\nPHP $db-\u0026gt;foo-\u0026gt;find(['x' =\u0026gt; 99]);\nRuby client[:foo].find(x: 99) → OP_MSG\nlength=180;requestID=0x1b73a9;responseTo=0;opCode=2013(=OP_MSG type)\nflags=0x00.0x00\nsection 1/1 = {\n\u0026nbsp; \u0026quot;find\u0026quot;:\u0026quot;foo\u0026quot;,\n\u0026nbsp; \u0026quot;filter\u0026quot;:{\u0026quot;x\u0026quot;:99.0},\n\u0026nbsp; \u0026quot;$clusterTime\u0026quot;:{ ... }},\n\u0026nbsp; \u0026quot;signature\u0026quot;:{ ... },\n\u0026nbsp; \u0026quot;$db\u0026quot;:\u0026quot;test\u0026quot;\n} → mongo::FindCmd::run   (A cursor object with first batch results) ← OP_MSG (as a reply)\nlength=180;requestID=0xb5a;responseTo=0x1b73a9;opCode=2013(=OP_MSG type)\nflags=0x00.0x00\nsection 1/1 = {\n\u0026nbsp; \u0026quot;cursor\u0026quot;:{\n\u0026nbsp; \u0026nbsp; \u0026quot;id\u0026quot;:{\u0026quot;$numberLong\u0026quot;:\u0026quot;0\u0026quot;},\n\u0026nbsp; \u0026nbsp; \u0026quot;ns\u0026quot;:\u0026quot;test.foo\u0026quot;,\n\u0026nbsp; \u0026nbsp; \u0026quot;firstBatch\u0026quot;:[\n\u0026nbsp; \u0026nbsp; {\u0026quot;_id\u0026quot;:ObjectId(\u0026quot;5b3433ad88d64ee7afb5dc80\u0026quot;), \u0026quot;x\u0026quot;:99.0,\u0026quot;order_cust_id\u0026quot;:\u0026quot;AF4R2109\u0026quot;}\n\u0026nbsp; ]\n\u0026nbsp; },\n\u0026nbsp; \u0026quot;ok\u0026quot;:1.0,\n\u0026nbsp; \u0026quot;operationTime\u0026quot;:{ ... },\n\u0026nbsp; \u0026quot;$clusterTime\u0026quot;:{ ... },\n\u0026nbsp; \u0026quot;signature\u0026quot;:{ ... },\n\u0026nbsp; \u0026quot;keyId\u0026quot;:{\u0026quot;$numberLong\u0026quot;:\u0026quot;0\u0026quot;}}}\n} ← ↲    A historical detour The above is latest-and-greatest OP_MSG format. At time of writing only the 3.6+ mongo shell and dev-branch drivers would be using it. In truth most driver versions are still being shoe-horned into the legacy OP_QUERY message type.\nPer its name OP_QUERY was meant to only be for queries, but was repurposed for mostly any type of request message. In its network packet fields it included a \u0026quot;fullCollectionName\u0026quot; field because queries always need a a db and collection name scope). But there are commands that don't have a collection scope (eg. replicaSetGetStatus, createUser) but don't have a dedicated wire protocol message type either. How to send them? The workaround for those cases was that \u0026quot;$cmd\u0026quot; was used as a dummy collection name at the end of the \u0026quot;fullCollectionName\u0026quot; field. This workaround became so standard that it is even set this way for commands such as find which do need a collection scope. You can see in the example below that the collection name \u0026quot;foo\u0026quot; has moved inside the BSON and is absent outside.\n   Legacy wire packet examples     OP_QUERY\nlength=215;requestId=0x6633483;responseTo=0;opCode=2004(=OP_QUERY type)\nfullCollectionName=\u0026quot;test.$cmd\u0026quot; //N.b. the dummy \u0026quot;$cmd\u0026quot; collection name numberToSkip=0;numberToReturn=0xffff\ndocument = {\n\u0026nbsp; \u0026quot;find\u0026quot;:\u0026quot;foo\u0026quot;,\n\u0026nbsp; \u0026quot;filter\u0026quot;:{\u0026quot;x\u0026quot;:99},\n\u0026nbsp; \u0026quot;lsid\u0026quot;:{ ... },\n\u0026nbsp; \u0026quot;$clusterTime\u0026quot;:{ ... },\n\u0026nbsp; \u0026quot;signature\u0026quot;:{ ... },\n\u0026nbsp; \u0026quot;keyId\u0026quot;:{\u0026quot;$numberLong\u0026quot;:\u0026quot;0\u0026quot;}}}\n}   OP_REPLY\nlength=301;requestId=0xbb8;responseTo=0x6633483;opCode=1(=OP_REPLY type)\nresponseFlags=0x08(=AwaitCapable)\ncursorID=0 //important for getMore cmds that follow, if any;\nstartingFrom=0;numberReturned=1\ndocument = {\n\u0026nbsp; \u0026quot;cursor\u0026quot;\n\u0026nbsp; {\n\u0026nbsp; \u0026nbsp; \u0026quot;firstBatch\u0026quot;:[\n\u0026nbsp; \u0026nbsp; \u0026nbsp; {\u0026quot;_id\u0026quot;:ObjectId(\u0026quot;5b3433ad88d64ee7afb5dc80\u0026quot;), \u0026quot;x\u0026quot;:99.0,\u0026quot;order_cust_id\u0026quot;:\u0026quot;AF4R2109\u0026quot;}\n\u0026nbsp; \u0026nbsp; ],\n\u0026nbsp; \u0026nbsp; \u0026quot;id\u0026quot;:{\u0026quot;$numberLong\u0026quot;:\u0026quot;0\u0026quot;},\n\u0026nbsp; \u0026nbsp; \u0026quot;ns\u0026quot;:\u0026quot;test.foo\u0026quot;},\n\u0026nbsp; \u0026nbsp; \u0026quot;ok\u0026quot;:1.0,\n\u0026nbsp; \u0026nbsp; \u0026quot;operationTime\u0026quot;:{ ... },\n\u0026nbsp; \u0026nbsp; \u0026quot;signature\u0026quot;:{ .. }\n\u0026nbsp; }\n}    My way of looking at is:\n In the beginning there were just collection editing or reading commands (query, insert, update, delete) and four wire packet types for those, plus a reply message type. The db+collection namespace was put in a network field, outside the BSON payload document. Soon there many more command types that the database server accepted. A generic command wire packet format was needed. The existing drivers (that needed to be supported for some time) started using OP_QUERY overloaded for this purpose. A generic command wire packet type OP_COMMAND was invented! And used by mongo shell v3.4(?) and between nodes in clusters and replica sets. But it didn't go mainstream. Instead the OP_MSG type has become the new standard, to be used by 4.2? era drivers. Neither the collection name or database name is in the network header fields - they'll be in \u0026quot;ns\u0026quot; (namespace) inside the BSON payload instead.  You might have noticed that there's no single field in the BSON command that says what sort of command the client is sending. Does the server run through a list of keys in fixed order until it gets a match? (E.g. if (commandMessage.hasKey(\u0026quot;find\u0026quot;) then --\u0026gt; FindCmd:run(), else if commandMessage.hasKey(\u0026quot;update\u0026quot;) -\u0026gt; UpdateCmd::run(), etc. ....?).\nNope, a simpler mechanism is used. From util/net/op_msg.h:\nStringData getCommandName() const { return body.firstElementFieldName(); }  A lesson from this is that order in BSON can matter (at least to MongoDB). Important for driver developers, but not application programmers as the driver API will take care of this point for you.\nWhat it looks like to the programmer I don't want to re-invent the documentation wheel for this part. MongoDB's official documentation tutorials are good and cover many language samples in one page. Some links for a couple of types of operations:\n Document insert example (Python, Java, Node.js, PHP, C#, Perl, Ruby, Scala) Query example (Python, Java, Node.js, PHP, C#, Perl, Ruby, Scala)  "
},
{
	"uri": "localhost:1313/en/connecting_guide/human_ix/mongo_shell/",
	"title": "The mongo shell",
	"tags": [],
	"description": "The simple truth about the mongo shell",
	"content": " What it is The mongo shell is just another client application. There, I said it.\nIt is not a special node within a MongoDB replica set or cluster. It is an application that connects and communicates with the mongod (or mongos) nodes with the same MongoDB Wire protocol TCP traffic that any other application could. If it was a black box rather than being open source, you could reverse-engineer it even without super-dooper elite hacker skills. It has no special sauce that gives it elevated privilege or better performance compared to what any MongoDB driver-using application can have.\nWhat is unique about the mongo shell compared to the thousands of other MongoDB-connected applications you might install on your computer is that is an interactive CLI (command line interpreter) a.k.a. REPL (read-evaluate-print loop). It's not the only MongoDB CLI that has ever existed, but it is the only popular one to date.\nWhy use it Having an interactive shell is a practical requirement for doing administration, so basically everyone will use it for that reason at least. Most people will also use it for learning. The MongoDB documentation uses mongo shell syntax all over too.\nConnection examples On the unix (or windows) shell you can specify connection options, and optionally input (a script file to run or a single string to run).\nIf you are not already familiar with the command-line arguments the mongo shell accepts please expand the following section.\n  Expand me...   The examples beneath show how to connect to:\n A replicaset named \u0026quot;merch_backend_rs\u0026quot; It has two normal, data-bearing nodes running at  dbsvrhost1:27017 (the current primary), dbsvrhost2:27017 (currently a secondary),  And an arbiter on a third host somewhere. The main user database is \u0026quot;orderhist\u0026quot;. There is a user \u0026quot;akira\u0026quot; with password \u0026quot;secret\u0026quot;, and the usual \u0026quot;admin\u0026quot; db is the authentication database (i.e. where the system.users and related system collections are).  Common usage forms shown below. See here for the all the options.\n# Most typical mongo --host dbsvrhost1:27017/orderhist -u akira -p secret --authenticationDatabase admin # Specify the replicaset name to guarantee a proper replset connection mongo --host merch_backend_rs/dbsvrhost1:27017,dbsvrhost2:27017/orderhist -u akira -p secret --authenticationDatabase admin # Using a mongodb URI connection string, the same as in your application code. mongo --host 'mongodb://akira:secret@dbsvrhost1:27017,dbsvrhost2:27017/orderhist?authSource=admin\u0026amp;replicaSet=merch_backend_rs' # If you have disabled authentication in the mongod configuration, and it is # running on port 27017 on localhost, and you want to use the \u0026quot;test\u0026quot; db ... # Bingo!, the naked command will work. mongo # Execute a javascript script file mongo --host dbsvrhost1:27017/orderhist -u akira -p secret --authenticationDatabase admin daily_report.js # Execute a javascript statement as a command-line argument. mongo --host dbsvrhost1:27017/orderhist_db -u akira -p secret --authenticationDatabase admin --eval 'var acnt = db.collection_a.count(); var bcnt = db.collection_b.count(); if (acnt != bcnt) print(\u0026quot;Reconcilliation error: Collection a and b counts differ by \u0026quot; + Math.abs(acnt - bcnt));'  In the case of sharded cluster do not add a replicaset parameter in the connection arguments. Just provide the hostname(s) and por(s) of the mongos node(s) you are connecting to.\n  Internals Although it is made with C++ the language that this CLI interprets is Javascript. Apart from a very small number of legacy, imperative-style command expressions such as \u0026quot;show databases\u0026quot;, \u0026quot;exit\u0026quot;, etc. everything is Javascript.\nShell parsing Legacy MySQL-like commands use \u0026lt;database_name\u0026gt; show databases show collections  Apart from \u0026quot;use database_name\u0026quot;, which sets the database namespace the client sends in the Wire Protocol requests, these legacy command expressions are all translated internally to a Javascript function. For example \u0026quot;show collections\u0026quot; is really:\n//From mongo/shell/utils.js //The real code behind \u0026quot;show collections\u0026quot;: if (what == \u0026quot;collections\u0026quot; || what == \u0026quot;tables\u0026quot;) { db.getCollectionNames().forEach(function(x) { print(x); }); return \u0026quot;\u0026quot;; }  Plain Javascript The mongo shell will process javascript with referring to any database context if you want to! Below are some client side-only expressions and functions, pretty much identical to those you can do in the native Javascript supported in web browsers etc.\nvar x = 1; for (i = 0; i \u0026lt; 100; i++) { print(i); } function max(a, b) { return a \u0026gt; b ? a : b; }  Javascript that acts with database connection objects Unless you use the --no-db argument there will be the \u0026quot;db\u0026quot; special global object which can be used to send db command messages over the connection to a MongoDB server.\nuse \u0026lt;database_name\u0026gt; //set current database namespace db.version() //database namespace doesn't affect this particular command //Because I did not capture the result into a variable (i.e. I didn't put \u0026quot;var version_result = …\u0026quot; at the front) // the shell will capture the return value from db.getVersion() and auto-print it here 3.4.4 db.serverStatus() ///database namespace doesn't affect this particular command //As before, the return value from the statement will be auto-printed. db.serverStatus() { \u0026quot;host\u0026quot; : \u0026quot;myhost.mydomain\u0026quot;, \u0026quot;version\u0026quot; : \u0026quot;3.4.4\u0026quot;, \u0026quot;process\u0026quot; : \u0026quot;mongod\u0026quot;, \u0026quot;pid\u0026quot; : NumberLong(2175), ... ... \u0026quot;ok\u0026quot; : 1 } var cursor = db.\u0026lt;collection_name\u0026gt;.find({\u0026quot;customer_id\u0026quot;: 10034}); //this command is affected by the database namespace while (cursor.hasNext()) { var doc = cursor.next(); printjson(doc); } ...  In the example above:\n \u0026lt;database_name\u0026gt; is set as the db scope. This will go in command objects put into MongoDB Wire protocol messages sent from here. It won't be changed there is another \u0026quot;use xxxxx\u0026quot; statement or something that implies it, like a db.getSiblingDB(...) function. db.getVersion() will create a buildinfo command as BSON object. Through javascript-interpreter-to-C++-code boundary and then the C++ driver library that is put that in wire protocol message message and send it the db server. The response travels those layers in reverse, finally ending with the buildinfo result in Javascript object, from which the version property is picked and printed. db.serverStatus() is a helper function that executes _db.adminCommand({serverStatus: 1})) instead. I.e. this time the BSON object being packed and set is {serverStatus: 1} compared to {hostinfo: 1}. At the return the whole object (rather than just one scalar value property) is pretty-printed onto the terminal output. A similar pattern at first to the last two comands, just that a {find: \u0026quot;database_name.collection_name\u0026quot;} BSON object is being sent. However this time there will be a cursor with results. Through the driver API each document in the cursor results will be passed separately with each iteration of the cursor. If more results need to be fetched from the server side getMore requests holding the cursor id value from the find command's result will be sent and read repeatedly until the cursor is exhausted (or times out) on the server side.  Ever-present db namespace The sent commands always includes a database namespace. You can change it at will (\u0026quot;use another_db_name\u0026quot;) so it is variable, but it can't be empty/null. Default is \u0026quot;test\u0026quot;.\nSome commands don't logically require a db namespace \u0026ndash; eg. isMaster, addShard, replSetGetStatus \u0026ndash; but they won't work unless it is set to \u0026quot;admin\u0026quot;. Many a time I've had those fail until I typed \u0026quot;use admin\u0026quot; and tried again. Some like isMaster you don't notice because you're probably never call it except by the a shell helper function (db.isMaster()) that sets it.\nCrystal ball gazing: Having said all this it isn't out the question that what is unnecessary will be removed in the future. The OP_MSG message format in particular doesn't require or even permit a db namespace in the network fields, so once older messages formats stop being supported some rationalization is possible. E.g. the db server (mongod or mongos) could just silently ignore the db name scope from the client when it is a command such as isMaster, serverStatus, etc.\nExplicit db connection objects You don't have to use the \u0026quot;db\u0026quot; global var if you don't want to. You can manually create other live MongoDB connections objects with connect(\u0026lt;conn_uri\u0026gt;), or new Mongo(\u0026lt;conn_uri\u0026gt;) and give those whatever variable name you like. It would be an untypical way to use the mongo shell however.\nTODO expand on what the wire protocol traffic is for all commands in the example above.\nRecap To recap the mongo shell:\n Uses the MongoDB wire protocol to communicate with MongoDB servers the same as any application It is C++ internally Makes use of a javascript engine library and \u0026quot;readline\u0026quot;-style line editor library to provide a live Javascript command line interpreter / REPL. It doesn't handle the wire protocol 'raw' or control TCP primitives itself. It uses the standard C++ MongoDB client driver for that. Can be used to run Javascript code for the sake of Javascript alone, but the purpose is communicate with the database There is one \u0026quot;db\u0026quot; MongoDB connection object created which represents the connection to the standalone mongod or replicaset of mongod nodes or mongos host you specified with the --host argument when you began the shell. (TODO LINK to connection URI page) The behind-the-scenes flow every time you execute a db.XXX() command:  You create documents as Javascript objects, and execute Javascript functions in the interpreter. The mongo shell converts the Javascript objects to BSON, and the functions to known MongoDB server commands, which are also serialized in a BSON format. These include the argument values (if any), puts it into the OP_MSG request (or legacy OP_QUERY or the v3.2(?) experimental OP_COMMAND format requests) and sends it over the network The server responds with a reply in BSON The mongo shell converts the reply to a javascript result, and the BSON data is converted to a Javascript object The converted-to-Javascript-binary-format result is assigned into a javascript variable if you set one, or auto-printed into the shell terminal if you did not.   Q. \u0026quot;But what about server-side Javascript? That's what MongoDB uses right?\u0026quot;\nNo, that's not what MongoDB uses. Well it can interpret and execute some javascript functions you send to it, but they're only for running within:\n a MapReduce command, or (Superseded by $expr in v3.6; removed v4.2): if using a $where operator in a find command, or (Deprecated v3.4; removed v4.2): as the \u0026quot;reduce\u0026quot;, \u0026quot;keyf\u0026quot; or \u0026quot;finalize\u0026quot; arguments in a group command.  These functions are javascript, but they get packed inside a special BSON datatype to be sent to the server and the mongod is the only program I know that has ever been programmed to unpack that format. Being javascript it is a lot slower than the native C++ processing in the mongod process.\n"
},
{
	"uri": "localhost:1313/en/connecting_guide/cs_nw_details/ha_connections/",
	"title": "Automatic failover",
	"tags": [],
	"description": "A light introduction regarding how MongoDB drivers will automatically respond to server failures",
	"content": "Although it hasn't been discussed in the book in detail so far, in the typical situation your client will be connected to a replica set, that is it will be sending writes to one node (the Primary) whilst also being connected to other nodes that are Secondaries. As long as the Primary is alive, accepting commands, and the other nodes continue to agree that it is the primary, that will continue without change.\nBut if the original primary node dies, or get cuts off network-wise from the other nodes, they will initiate a replica set election and one of them will become the new primary.\nThere be may some writes to the original primary that will have to be rolled back, particularly in an unbalanced network partition situation. That is an issue that means the rolled back operations will have to be examined manually and re-applied manually by administrators after the incident.\nThe election would take a fraction of a second usually (2 seconds at most), faster than any human is going to be able to react, so you want the application to automatically switch to use the new primary.\nQ. What do you program to make sure the client application send requests to the new primary, and avoid having every single thread in every single process throw endless repeating 'socket exception' or 'write rejected not primary' errors?\nA. Nothing. Because all the drivers have replica set automatic failover logic programmed into them you can't program (and don't need to program) anything extra to achieve re-routing to the surviving nodes.\nFrom the point of view of the application code using a MongoDB connection, database, or collection object it can continue to use the same object. The driver will route the reads and writes to the new primary. If you have explicitly requested reads to come from a non-primary node (possible with a feature called readPreference, to be discussed later) the connection for those will be changed away from the new primary node too.\nSo the challenge of staying connected is solved for you out of the box whichever driver you use.\nWhat is not handled is what to do with rolled back data. Rollbacks can occur in the case that the original primary doesn't step down immediately, and accepts some writes in the brief time before it determines it has lost the status updates from the other nodes and steps itself down. This will be explained more in the \u0026quot;Making MongoDB stable\u0026quot; chapter.\n"
},
{
	"uri": "localhost:1313/en/connecting_guide/human_ix/",
	"title": "How to connect from your app or a terminal",
	"tags": [],
	"description": "First things first: how you connect to the database service as a client app or administrator",
	"content": "  Connection string URI  MongoDB connection URI syntax\n The mongo shell  The simple truth about the mongo shell\n "
},
{
	"uri": "localhost:1313/en/guide_intro/",
	"title": "What you can do with MongoDB",
	"tags": [],
	"description": "A dash through the top reasons to use MongoDB",
	"content": " Develop faster Mostly everyone who has used one of the 'NoSQL' databases which came into popularity post-2010, of which MongoDB is the most popular, already appreciate this. But for those of you still using relational databases the key reasons for the higher development productivity are:\n Reduced lines of code You don't need to perform a full mental switch between the paradigm of your application's data structure v.s. the server-side data storage mechanism.  You are a glucose-powered computer and context change is expensive. Only so much glucose can be converted by your neurons into thought-sparks a day, so save your sparks for things that are more valuable to you.\nBroadest client language support Want to do things quicker by using more developers / tools? For example your Web front-end has been created in language X, but the data scientists that will mine gold from the big data need to use language Y? MongoDB has got you covered - C, C++, C#, Erlang, Go, Java, Node.js, Perl, PHP, Python, Ruby and Scala are supported.\nThe simplicity of the client API will also reduce the technical debt of your codebase significantly. To the original developer this may seem unimportant, but for the development department that owns the technology it is more important than the speed of new feature development.\nWrite and read data faster This has always been my favourite feature of MongoDB.\nLet's take a trip back in time, to 2010 or so. The first MongoDB version I was using was 1.6, and I had a task to load a dataset of some 10's of GB. I can't remember the client program, but it might have been mongoimport.\nAs the data load progressed:\n I was pleasantly surprised by the rate of document inserts. I was a little shocked by the rate of inserts. I was getting suspicious of the insertion rate. Was the counter just a client-side lie? (No, I confirmed server-side.) I started sanity-checking the numbers, by datasize too. I arrived at a figure ~30 MB/s. 30 MB/s reminded me of something. At the time commodity HDD specs advertised 30MB/s write speeds. I checked the server's disk specs. They were the same 30 MB/s rate.  The takeaway for me was the hardware specs were no longer some sort of fantasy numbers way above the user's reality, which was a given for RDBMS-using application developers until then. If the hardware manufacturers have engineered their equipment to flick x million or billion electrons per second from one silicon nano-suburb to another, I could now use all those electrons for my data purposes.\nWith the change in hardware-land to SSDs, and furthermore MongoDB's change to the WiredTiger storage engine, MongoDB users now enjoy throughput and latency somewhat higher than the puny 30MB/s figure above. But the key point is to expect MongoDB to redline your hardware's throughput and/or latency by the volume of your data being moved, without the database software eating a noticeable chunk of the server capacity for itself.\nGo big The growth of e-commerce and social networking in the noughties lead to many thousands of businesses having a problem that was limited to few before. This was dataset sizes that exceeded the capacity of the biggest server you could afford to buy. If your user base was large, well, you either became one of the few companies that engineered around this by getting good at distributed data in your server application, or you limited data detail and panicked about whether you'd last the next 2 months before the server RAM and disk upgrades were delivered.\nThe NoSQL databases for the most part came with a huge benefit for this businesses / websites - easy data partitioning. You don't program the distribution logic in your application, instead you leave it to the database driver or the db server node you connect to.\nThe NoSQL databases mostly also included TODO LINK replication, making automatic database failover another thing that happens on the other 'side' of the database driver.\nWhich field(s) should be chosen to partition data is still a very important decision that you need to make for yourself, but after that your MongoDB cluster will allow you to grow your data up to (Single server storage size) x (100's).\nGet bigger quickly Starting with a single, unsharded MongoDB replica set is not a problem if suddenly you find you data volume growing. A single replica set can be dynamically converted, in configuration, to being the first shard of a one-shard MongoDB cluster. With no downtime or any reinsertion of your user data you can gain the ability to add new shards. Add one, two, as many as are needed, and the first cluster's data will be redistributed automatically until the number of documents in collections is balanced between the shards.\nThis has no impact on the logical view of the data to the client. To the client it is as though there is one server with larger capacity. Even document data that might happen to be in the process of being moved from one shard to another as part of shard balancing will not experience an error or delay. (It will delay the background move instead, if the access is write).\nBe small You can also be small - MongoDB does not hang some performance-lowering burden of distributed data management on your database server, or place configuration burden on you as a database administrator, if you aren't using it.\nYou don't even have to have a replica set if, in a rare sort of use case, you can afford for your database to be down (say if a data center's power goes out) and furthermore don't care if the data is lost (say if the hard disk suffers irreversible corruption). MongoDB can run as a standalone mongod process and this lets you forgo the cost of having a second or third server. (Starting from v4.0 technically all nodes must be in a replica set by configuration, but that can be single-node replica set.)\nGet smaller quickly I'm just kidding. But if you weren't, yes, you can use remove (== document delete), drop (== whole collection drop), rs.remove(\u0026lt;replica member\u0026gt;) and removeShard.\nSurvive server, data center failures MongoDB replica set members contain copies of each other's data to within whatever limit of time it takes for an update on the primary to be replicated to the secondaries. This can be just a millisecond in the better cases.\nAn important corollary to this is: the drivers (i.e. the MongoDB API library you use in your code to connect to MongoDB) are all replicaset-aware, regardless of which language you are version.\nIf you are using sharding, you will connect to a mongos node. The mongos node does the failover handling in that case.\nSo if a server dies:\n The remaining replica set nodes will notice this (default is with \u0026lt;= 2 seconds, the 'heartbeat' cycle). If the server that died was the primary, they will hold a new election and one of the prior secondaries becomes the new primary. There is a dynamic replicaset state shared between them which is updated. When the former primary is restarted it will receive and act accordingly to that new state where it is a secondary, not try to continue as it was before it's halt. The clients that were connected, with the replica-set aware driver code, will detect the failure of the read/write they were performing at the time. Apart from the 'blip' of reads and writes that failed because they were en-route to the former primary just about the time it died, the application's database functionality remains up. E.g. if you were serving 10,000 web page request a minute some, say dozens, will have database errors. The web pages served before and after will be unaffected. You don't have to accept that the client fails to perform it's intended logic during the period of time between the first primary's crash and the new one stepping up. The type of error returned in the event of a lost primary will allow you to recognize that a new primary will shortly step up, and that you can try to do the same thing again (say with try-catch block). MongoDB drivers do not automatically retry for a good reason though - whether something should be retried or not depends on your application's requirements. So it is left to programmers to explicity choose what to do - retry, or not. Redo writes assuming the original context is still valid, or not. Just try the write again, and if there is a duplicate error you could assume the write originally succeeded (and was replicated to the secondary node that subsequently became the new primary)  Know the inside out Diagnostic information MongoDB includes diagnostic information.\n Log files db.serverStatus() Configuration:  db.cmdLineOptions() rs.status(), rs.conf() sh.status() The sharding config db.   These are evidence you can examine to learn a lot about the state of your MongoDB instances.\nGraphical tools are not included in the normal server and client installation packages, but you can find them in MongoDB's cloud utlities, or third-party metric monitoring tools.\nSource code A nice feature, for the C++ programmers especially, is that the source code (excluding enterprise modules such as LDAP and Kerberos authentication, auditing, etc.) is publicly available.\n"
},
{
	"uri": "localhost:1313/en/connecting_guide/cs_nw_details/",
	"title": "Client-Server network communication",
	"tags": [],
	"description": "The shape of network communication between MongoDB clients and server",
	"content": "  Drivers and \u0026#39;the wire\u0026#39;  Putting perspective on what a MongoDB driver is through a description of the shape and behaviour of your client requests (and server replies) as TCP traffic\n Automatic failover  A light introduction regarding how MongoDB drivers will automatically respond to server failures\n "
},
{
	"uri": "localhost:1313/en/connecting_guide/",
	"title": "Connecting to MongoDB",
	"tags": [],
	"description": " ",
	"content": " Chapter 2 Connecting to MongoDB  How to connect from your app or a terminal  First things first: how you connect to the database service as a client app or administrator\n Client-Server network communication  The shape of network communication between MongoDB clients and server\n "
},
{
	"uri": "localhost:1313/en/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "localhost:1313/en/credits/",
	"title": "Credits for the Learn Theme for Hugo",
	"tags": [],
	"description": "",
	"content": " Contributors Thanks to them  for making Open Source Software a better place !\n.ghContributors{ display:flex; flex-flow: wrap; align-content: flex-start } .ghContributors  div{ width: 50% ; display: inline-flex; margin-bottom: 5px; } .ghContributors  div label{ padding-left: 4px ; } .ghContributors  div span{ font-size: x-small; padding-left: 4px ; }   @matcornic 149 commits   @matalo33 37 commits   @lierdakil 16 commits   @gwleclerc 13 commits   @mdavids 10 commits   @coliff 9 commits   @ozobi 5 commits   @Xipas 5 commits   @pdelaby 4 commits   @Chris-Greaves 3 commits   @mreithub 3 commits   @massimeddu 3 commits   @willwade 3 commits   @denisvm 2 commits   @gpospelov 2 commits   @tanzaho 2 commits   @wikijm 2 commits   @lfalin 2 commits   @alexvargasbenamburg 1 commits   @afs2015 1 commits   @arifpedia 1 commits   @MrMoio 1 commits   @ChrisLasar 1 commits   @IEvangelist 1 commits   @giuliov 1 commits   @haitch 1 commits   @ImgBotApp 1 commits   @RealOrangeOne 1 commits   @JohnBlood 1 commits   @kamilchm 1 commits   @lloydbenson 1 commits   @sykesm 1 commits   @654wak654 1 commits   @PierreAdam 1 commits   @ripienaar 1 commits   @EnigmaCurry 1 commits   @taiidani 1 commits   @exKAZUu 1 commits   @shelane 1 commits   @tedyoung 1 commits   @Thiht 1 commits   @editicalu 1 commits   @fossabot 1 commits   @kamar535 1 commits   @nonumeros 1 commits   @pgorod 1 commits   @proelbtn 1 commits   And a special thanks to @vjeantet for his work on docdock, a fork of hugo-theme-learn. v2.0.0 of this theme is inspired by his work.\nPackages and libraries  mermaid - generation of diagram and flowchart from text in a similar manner as markdown font awesome - the iconic font and CSS framework jQuery - The Write Less, Do More, JavaScript Library lunr - Lunr enables you to provide a great search experience without the need for external, server-side, search services... horsey - Progressive and customizable autocomplete component clipboard.js - copy text to clipboard highlight.js - Javascript syntax highlighter modernizr - A JavaScript toolkit that allows web developers to use new CSS3 and HTML5 features while maintaining a fine level of control over browsers that don't support  Tooling  Netlify - Continuous deployement and hosting of this documentation Hugo  "
},
{
	"uri": "localhost:1313/en/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "localhost:1313/en/",
	"title": "Top page",
	"tags": [],
	"description": "",
	"content": " Akira's guide to MongoDB A guide aimed towards:\n Server / database administrators who will be running MongoDB servers, or Application developers who want a deep understanding of the performance, communication and high-availability behaviour of MongoDB clusters.\n  What's special about this guide compared to others?\n The chapter structure and topic emphasis is shaped by my experience working for MongoDB support. That is it is weighted according to what sort of questions and conceptual gaps I know are more common amongst professional MongoDB users, including those with many years experience of relational databases. The more verbatim details that we all forget (and have to look up later anyway) are not included here. Instead there will only be links to the right page for it in the official https://docs.mongodb.com/manual/ documentation site. Viva la internet! Driver API usage will be explained in tandem with Mongo Wire Protocol as it is the common reality underlying all of the drivers. It is also the key piece of the picture when understanding how and when client requests and the server responses enter and leave the mongod and mongos server processes.  "
}]